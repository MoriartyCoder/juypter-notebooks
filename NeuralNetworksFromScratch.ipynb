{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0d9d65-ca49-425c-8c00-cce901e588f8",
   "metadata": {},
   "source": [
    "# Neural Networks from Scratch (sentdex)\n",
    "\n",
    "https://www.youtube.com/watch?v=Wo5dMEP_BbI&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe03aca-cedd-448f-86cd-754db7229d9a",
   "metadata": {},
   "source": [
    "## Chapter 1\n",
    "\n",
    "Each neuron is connected to all neurons of the next layer. OR Each neuron has a unique connection to every single previous neuron.\\\n",
    "Each connection has a weight. \\\n",
    "Each neuron has a bias for all connections.\n",
    "\n",
    "\n",
    "* The hard part is the tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138374b-dd59-4465-89d2-36ca3fec24ba",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef5d2d8-3ae5-45ef-9a62-087b96e3843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32425d3-6fca-4354-b0b6-fd1d6b50c652",
   "metadata": {},
   "source": [
    "# Chapter 3/Dot-Product\n",
    "\n",
    "a⋅b=2⋅1+3⋅0+4⋅(−1)=2+0−4=−2\n",
    "\n",
    "Dump:\n",
    "Beim Dot-Product wird jedes Element des Arrays mit dem Elements des selben Indexes multipliziert und die Summe der Ergebnisse genommen.\n",
    "Für Neuronen funktioniert das gut weil, jedes Einzelne für jeden Input ein eigenes Gewicht hat. \\\n",
    "Es ist zudem eine Norm! <- Falsch! Eine Norm nimmt nur einen Vektor, aber das hier hat zwei!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f95ce1a-d9b2-4b1c-979c-411919d3ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46041384,  1.30792158,  1.76829082,  0.90843755,  0.54348603],\n",
       "       [-0.8714247 , -2.40524565, -0.03374424, -0.02242139,  0.95368656],\n",
       "       [-1.25421645,  0.49676027, -0.46174956, -0.68440205, -0.34709037],\n",
       "       [ 0.50354313,  0.49701205,  1.68187027,  0.19448532, -2.22208777]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74830d6a-8a14-4feb-bf9c-7c4d38c10b61",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "\n",
    "The result of all inputs times their weights plus bias is called *logits*. It gets pluged into a activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694db46-d284-450d-ad18-ed14058d82db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
